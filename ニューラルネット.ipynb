{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークの基礎を理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワークスクラッチの検証にはMNISTデータセットを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練用6万枚、テスト用1万枚の28×28ピクセルの白黒画像、およびそれらが0〜9のどの数字であるかというラベル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "#print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像データの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像データは符号なし8ビット整数のuint8型で保持されることが一般的ですが、plt.imshowはより自由な配列を画像として表示することが可能です。例えば、以下のようにマイナスの値を持ったfloat64型の浮動小数点であってもエラーにはならないし、先ほどとまったく同じ風に表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float) # float型に変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "#print(image) # 値を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9f6b498a30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, 'gray', vmin = 0, vmax = 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像関係のライブラリではこの自動的なスケーリングが思わぬ結果を生むことがあるので、新しいメソッドを使うときには確認しておきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、正解ラベルは0から9の整数ですが、ニューラルネットワークで多クラス分類を行う際には one-hot表現 に変換します。scikit-learnのOneHotEncoderを使用したコードが以下です。このone-hot表現による値はそのラベルである確率を示していることになるため、float型で扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n",
      "(48000,)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000,)\n",
      "(48000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに、訓練データ6万枚の内2割を検証データとして分割してください。訓練データが48000枚、検証データが12000枚となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ミニバッチ処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これまでの機械学習スクラッチでは、すべてのサンプルを一度に計算していました。しかし、ニューラルネットワークではデータを分割して入力する 確率的勾配降下法 が一般的です。分割した際のひとかたまりを ミニバッチ 、そのサンプル数を バッチサイズ と呼びます。\n",
    "\n",
    "\n",
    "今回はバッチサイズを20とします。今回使う訓練データは48000枚ですから、48000÷20で2400回の更新を繰り返すことになります。ニューラルネットワークではこれを2400回 イテレーション（iteration） すると呼びます。訓練データを一度すべて見ると1回の エポック（epoch） が終わったことになります。このエポックを複数回繰り返し、学習が完了します。\n",
    "\n",
    "\n",
    "これを実現するための簡素なイテレータを用意しました。for文で呼び出すと、ミニバッチを取得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        # バッチサイズ\n",
    "        self.batch_size = batch_size\n",
    "        # ランダムシードの固定\n",
    "        np.random.seed(seed)\n",
    "        # permutationは引数に配列を渡すとランダムに並び替えて返す\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0])) #Xの行数だけ公差配列を作る\n",
    "        # X,y両方を並べ替えた配列を作る\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        \n",
    "        # int型に変形させる\n",
    "        # astype(np.int)\n",
    "        \n",
    "        # 小数点以下を切り上げ、正に対して無限大に\n",
    "        ce_ = np.ceil\n",
    "        # 整数型になる\n",
    "        self._stop = ce_(X.shape[0]/self.batch_size).astype(np.int)\n",
    "        \n",
    "        # 整数が帰ってくる\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "        # p0の次のバッチの開始番号がp1となる\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "    \n",
    "        # 初期値0のカウンタ変数を返す\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "        # \n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            # マイナスの値になった場合、エラーにする\n",
    "            raise StopIteration()\n",
    "        # p0,p1を更新して次の場所を返す\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### このクラスをインスタンス化し、for文を使うことでミニバッチが取り出せます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train=48000,y_train=48000\n",
    "# get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "# print(len(get_mini_batch)) # 2400\n",
    "# print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "# print(type(get_mini_batch[5]))\n",
    "# # 2400回繰り返す\n",
    "# for mini_X_train, mini_y_train in get_mini_batch:\n",
    "#     # このfor文内でミニバッチが使える\n",
    "    \n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークの学習はフォワードプロパゲーションとバックプロパゲションの繰り返しになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】重みの初期値を決めるコードの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークの各層の重みの初期値を決めるコードを作成してください。\n",
    "\n",
    "\n",
    "重みの初期値はさまざまな方法が提案されていますが、今回はガウス分布による単純な初期化を行います。バイアスに関しても同様です。\n",
    "\n",
    "\n",
    "以下のコードを参考にしてください。標準偏差の値sigmaはハイパーパラメータです。発展的な重みの初期化方法については次のSprintで扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features = 784\n",
    "# n_nodes1 = 400\n",
    "# n_nodes2 = 200\n",
    "# n_output = 10\n",
    "# sigma = 0.01 # ガウス分布の標準偏差\n",
    "#self.W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "# self.W1: (784, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 重みとバイアス\n",
    "# self.W1 = sigma * np.random.randn(n_features,n_nodes1) #第一層の重み\n",
    "# self.W2 = sigma * np.random.randn(n_nodes1,n_nodes2) #第二層の重み\n",
    "# self.W3 = sigma * np.random.randn(n_nodes2,n_output) #第三層の重み\n",
    "# self.B1 = sigma * np.random.randn(n_nodes1) #第一層のバイアス\n",
    "# self.B2 = sigma * np.random.randn(n_nodes2) #第二層のバイアス\n",
    "# self.B3 = sigma * np.random.randn(n_output) #第三層のバイアス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】フォワードプロパゲーションの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三層のニューラルネットワークの フォワードプロパゲーション を作成してください。以下の説明ではノード数は1層目は400、2層目は200としますが、変更しても構いません。\n",
    "\n",
    "\n",
    "各層の数式を以下に示します。今回はそれぞれの記号が表す配列が、実装上どのようなndarrayのshapeになるかを併記してあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「1層目」\n",
    "\n",
    "$$\n",
    "A_1=X⋅W_1+B_1\n",
    "$$\n",
    "\n",
    "$X$ : 特徴量ベクトル (batch_size, n_features)\n",
    "\n",
    "\n",
    "$W_1$ : 1層目の重み (n_features, n_nodes1)\n",
    "\n",
    "\n",
    "$B_1$ : 1層目のバイアス (n_nodes1,)\n",
    "\n",
    "\n",
    "$A_1$ : 出力 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "「1層目の活性化関数」\n",
    "\n",
    "$$\n",
    "Z_1=f(A_1)\n",
    "$$\n",
    "\n",
    "$f()$ : 活性化関数\n",
    "\n",
    "\n",
    "$Z_1$ 出力 (batch_size, n_nodes1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「2層目」\n",
    "\n",
    "$$\n",
    "A_2=Z_1⋅W_2+B_2\n",
    "$$\n",
    "\n",
    "$W_2$ : 2層目の重み (n_nodes1, n_nodes2)\n",
    "\n",
    "\n",
    "$B_2$ : 2層目のバイアス (n_nodes2,)\n",
    "\n",
    "\n",
    "$A_2$ : 出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "「2層目の活性化関数」\n",
    "\n",
    "$$\n",
    "Z_2=f(A_2)\n",
    "$$\n",
    "\n",
    "$f()$ : 活性化関数\n",
    "\n",
    "\n",
    "$Z_2$ 出力 (batch_size, n_nodes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「3層目（出力層）」\n",
    "\n",
    "$$\n",
    "A_3=Z_2⋅W_3+B_3\n",
    "$$\n",
    "\n",
    "$W_3$ : 3層目の重み (n_nodes2, n_output)\n",
    "\n",
    "\n",
    "$B_3$ : 3層目のバイアス (n_output,)\n",
    "\n",
    "\n",
    "$A_3$ : 出力 (batch_size, n_output)\n",
    "\n",
    "\n",
    "「3層目の活性化関数」\n",
    "\n",
    "$$\n",
    "Z_3=softmax(A_3)\n",
    "$$\n",
    "\n",
    "$softmax()$ : ソフトマックス関数\n",
    "\n",
    "\n",
    "$Z_3$ 出力 (batch_size, n_output)\n",
    "\n",
    "\n",
    "$Z_3$ は各ラベル（0〜9）に対する確率の配列である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 活性化関数（フォワードプロバゲーション）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "活性化関数を作成し、フォワードプロパゲーションの中で使用します。切り替えられるように実装することを推奨しますが、片方でも構いません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「シグモイド関数」\n",
    "\n",
    "$$\n",
    "f(Z)=sigmoid(A)=1/(1+exp(−A))\n",
    "$$\n",
    "\n",
    "指数関数 $exp(-A)$ の計算はnp.expを使用してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「ハイパボリックタンジェント関数」\n",
    "\n",
    "\n",
    "次の数式で表されますが、np.tanhひとつで実現できます。\n",
    "\n",
    "$$\n",
    "f(Z)=tanh(A)=(exp(A)−exp(−A)) / (exp(A)+exp(−A))\n",
    "$$ \n",
    "\n",
    "＊現在ではこれらの代わりにReLUと呼ばれる活性化関数が一般的です。次のSprintで扱います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ソフトマックス関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソフトマックス関数を作成し、フォワードプロパゲーションの中で使用します。これも活性化関数の一種ですが、多クラス分類の出力層で使われる特性上、区別して扱われることが多いです。\n",
    "\n",
    "\n",
    "次の数式です。\n",
    "\n",
    "$$\n",
    "Z_{3_k}=exp(A_{3k})/∑^{n_c}_{i=1}exp(A_{3i})\n",
    "$$\n",
    "\n",
    "$Z_{3_k}$ : $k$ 番目のクラスの確率ベクトル (batch_size,)\n",
    "\n",
    "\n",
    "$A_{3_k}$ : $k$ 番目のクラスにあたる前の層からのベクトル (batch_size,)\n",
    "\n",
    "\n",
    "$n_c$ : クラスの数、n_output。今回のMNISTでは10。\n",
    "\n",
    "\n",
    "分母はすべてのクラスに相当する値を指数関数に通した上で足し合わせたものです。その中で、分子に $k$ 番目のクラスを持ってくることで、 $k$ 番目のクラスである確率が求まります。\n",
    "\n",
    "\n",
    "これを10クラス分計算し、合わせたものが $Z_3$ です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 20 # バッチサイズ\n",
    "# n_features = 784 # 特徴量の数\n",
    "# n_nodes1 = 400 # 1層目のノード数\n",
    "# n_nodes2 = 200 # 2層目のノード数\n",
    "# n_output = 10 # 出力のクラス数（3層目のノード数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 活性化関数、今回はシグモイド関数\n",
    "# def _sigmoid(self,X):\n",
    "#     return 1 /(1 + np.exp(-X))\n",
    "\n",
    "# # ソフトマックス関数\n",
    "# def _softmax(self,X):\n",
    "#     c = np.max(X)\n",
    "#     exp_x = np.exp(X - c)\n",
    "#     sum_exp_x = np.sum(exp_x)\n",
    "#     y = exp_x / sum_exp_x\n",
    "#     return y\n",
    "\n",
    "# def forward(self,X):\n",
    "#     \"\"\"1層目\"\"\"\n",
    "#     self.A1 = np.matmul(X,self.W1) + self.B1\n",
    "#     self.Z1 = self._sigmoid(self.A1)\n",
    "\n",
    "#     \"\"\"2層目\"\"\"\n",
    "#     self.A2 = np.matmul(self.Z1,self.W2) + self.B2\n",
    "#     self.Z2 = self._sigmoid(self.A2)\n",
    "\n",
    "#     \"\"\"3層目\"\"\"\n",
    "#     self.A3 = np.matmul(self.Z2,self.W3) + self.B3\n",
    "#     self.Z3 = self._softmax(self.A3)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】交差エントロピー誤差の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目的関数（損失関数）を作成します。\n",
    "\n",
    "\n",
    "多クラス分類の目的関数である交差エントロピー誤差 $L$ は次の数式です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "L=−1/{n_b}∑^{n_b}_j∑^{n_c}_ky_{jk}log(z{3_jk})\n",
    "$$\n",
    "\n",
    "$y_{ij}$ : $j$ 番目のサンプルの $k$ 番目のクラスの正解ラベル（one-hot表現で0か1のスカラー）\n",
    "\n",
    "\n",
    "$z_{3_ij}$ : $j$ 番目のサンプルの $k$ 番目のクラスの確率（スカラー）\n",
    "\n",
    "\n",
    "$n_{b}$ : バッチサイズ、batch_size\n",
    "\n",
    "\n",
    "$n_{c}$ : クラスの数、n_output（今回のMNISTでは10）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "サンプル1つあたりの誤差が求まります。\n",
    "\n",
    "\n",
    "実数におけるlog(x)の定義域は0 < xです。したがって、logの中身がとても小さい値になってしまったときエラーを起こします。そこでlogの中に1e-7を足すことでエラーを回避できます。\n",
    "\n",
    "\n",
    "こういった処理はlogに限らず、さまざまな場所で出てくることがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 交差エントロピー誤差\n",
    "# def cross_entro_error(z,y,batch_size=20,n_output=10):\n",
    "#     # ダブルシグマの合計値を入れるために０で初期化\n",
    "#     to_sum = 0\n",
    "\n",
    "#     # バッチの数（今回は２０）繰り返す\n",
    "#     for j in range(batch_size):\n",
    "#         # クラスの数（今回は１０）繰り返す\n",
    "#         for k in range(n_output):\n",
    "#             sum_k = y[j,k]*np.log(self.Z3[j,k])\n",
    "#             to_sum += sum_k\n",
    "\n",
    "#     L = (-1/batch_size)*to_sum\n",
    "    \n",
    "#     return L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】バックプロパゲーションの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三層のニューラルネットワークのバックプロパゲーションを作成してください。確率的勾配降下法を行う部分です。\n",
    "\n",
    "\n",
    "数式を以下に示します。\n",
    "\n",
    "\n",
    "まず、i層目の重みとバイアスの更新式です。 $W_i$ と $B_i$ に対し、更新後の $W_i^{\\prime}$ と $B_i^{\\prime}$ は次の数式で求められます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "W′_i=W_i−α\\frac{\\partial L}{\\partial W_i}\n",
    "$$\n",
    "$$\n",
    "B′_i=B_i−α\\frac{\\partial L}{\\partial B_i}\n",
    "$$\n",
    "\n",
    "$\\alpha$ : 学習率（層ごとに変えることも可能だが、基本的にはすべて同じとする）\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_i}$ : $W_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_i}$ : $B_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "＊この勾配はミニバッチのサンプル数分の合計または平均を考えます。ここでは合計を計算します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この更新方法はSprint3線形回帰やsprint4ロジスティック回帰における最急降下法と同様です。より効果的な更新方法が知られており、それは次のSprintで扱います。\n",
    "\n",
    "\n",
    "勾配 $\\frac{\\partial L}{\\partial W_i}$ や $\\frac{\\partial L}{\\partial B_i}$ を求めるために、バックプロパゲーションを行います。以下の数式です。ハイパボリックタンジェント関数を使用した例を載せました。シグモイド関数の場合の数式はその後ろにあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「3層目」\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_3}=1/{n_b}(Z_3−Y)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial B_3}=∑^{n_b}_j\\frac{\\partial L}{\\partial A_{3_j}}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_3}=Z^T_2⋅\\frac{\\partial L}{\\partial A_3}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial Z_2}=\\frac{\\partial L}{\\partial A_3}⋅W^T_3\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_3}$ : $A_3$ に関する損失 $L$ の勾配 (batch_size, n_output)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_{3_j}}$ : j番目のサンプルの$A_3$ に関する損失 $L$ の勾配 (n_nodes2,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_3}$ : $B_3$ に関する損失 $L$ の勾配 (n_output,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_3}$ : $W_3$ に関する損失 $L$ の勾配 (n_nodes2, n_output)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ に関する損失 $L$ の勾配 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$Z_{3}$ : ソフトマックス関数の出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$Y$ : 正解ラベル (batch_size, n_output)\n",
    "\n",
    "\n",
    "$Z_{2}$ : 2層目の活性化関数の出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$W_3$ : 3層目の重み (n_nodes2, n_output)\n",
    "\n",
    "\n",
    "$n_{b}$ : バッチサイズ、batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「2層目」\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_2}=\\frac{\\partial L}{\\partial Z_2}⊙(1−tanh^2(A_2))\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial B_2}=∑^{n_b}_j \\frac{\\partial L}{\\partial A_{2_j}}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_2}=Z^T_1⋅\\frac{\\partial L}{\\partial A_2}\n",
    "$$\n",
    "$$_\n",
    "\\frac{\\partial L}{\\partial Z_1}=\\frac{\\partial L}{\\partial A_2}⋅W^T_2\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_2}$ : $A_2$ に関する損失 $L$ の勾配 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_{2_j}}$ : j番目のサンプルの$A_2$ に関する損失 $L$ の勾配 (n_nodes2,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_2}$ : $B_2$ に関する損失 $L$ の勾配 (n_nodes2,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_2}$ : $W_2$ に関する損失 $L$ の勾配 (n_nodes1, n_nodes2)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ に関する損失 $L$ の勾配 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$A_2$ : 2層目の出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$Z_{1}$ : 1層目の活性化関数の出力 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$W_2$ : 2層目の重み (n_nodes1, n_nodes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「1層目」\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_1}=\\frac{\\partial L}{\\partial Z_1}⊙(1−tanh^2(A_1))\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial B_1}=∑^{n_b}_j \\frac{\\partial L}{\\partial A_{1_j}}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_1}=X^T⋅\\frac{\\partial L}{\\partial A_1}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_1}$ : $A_1$ に関する損失 $L$ の勾配 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_{1_j}}$ : j番目のサンプルの$A_1$ に関する損失 $L$ の勾配 (n_nodes1,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_1}$ : $B_1$ に関する損失 $L$ の勾配 (n_nodes1,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_1}$ : $W_1$ に関する損失 $L$ の勾配 (n_features, n_nodes1)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_1}$ : $Z_1$ に関する損失 $L$ の勾配 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$A_1$ : 1層目の出力 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$X$ : 特徴量ベクトル (batch_size, n_features)\n",
    "\n",
    "\n",
    "$W_1$ : 1層目の重み (n_features, n_nodes1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "《補足》\n",
    "\n",
    "\n",
    "活性化関数にシグモイド関数を使用した場合は、次のようになります。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_2}=\\frac{\\partial L}{\\partial Z_2}⊙(1−sigmoid(A_2))⊙sigmoid(A_2)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_1}=\\frac{\\partial L}{\\partial Z_1}⊙(1−sigmoid(A_1))⊙sigmoid(A_1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def back_proba(self,X,y):\n",
    "#     # X,yを入力すると3-1層を通過して最終出力値を返す仕組み\n",
    "    \n",
    "#     \"\"\"3層目\"\"\"\n",
    "#     # 重みに対する勾配\n",
    "#     bA3 = (self.Z3 - y)/self.batch_size\n",
    "#     bW3 = np.matmul(self.Z2.T,bA3)\n",
    "#     # バイアスに対する勾配\n",
    "#     bB3 = np.sum(bA3,axis = 0)\n",
    "    \n",
    "#     \"\"\"2層目\"\"\"\n",
    "#     # 重みに対する勾配\n",
    "#     bZ2 = np.matmul(bA3,self.W3.T)\n",
    "#     bA2 = bZ2 * (1 - self._sigmoid(self.A2))*self._sigmoid(self.A2)\n",
    "#     bW2 = np.matmul(self.Z1.T,bA2)\n",
    "#     # バイアスに対する勾配\n",
    "#     bB2 = np.sum(bA2,axis = 0)\n",
    "    \n",
    "#     \"\"\"1層目\"\"\"\n",
    "#     # 重みに対する勾配\n",
    "    \n",
    "#     bZ1 = np.matmul(bA2,self.W2.T)\n",
    "#     bA1 = bZ1 * (1 - self._sigmoid(self.A1))*self._sigmoid(self.A1)\n",
    "#     bW1 = np.matmul(X.T,bA1)\n",
    "#     # バイアスに対する勾配\n",
    "#     bB1 = np.sum(bA1,axis = 0)\n",
    "    \n",
    "#     # 各勾配に学習率をかけて更新\n",
    "#     self.W3 -= self.lr * bW3\n",
    "#     self.B3 -= self.lr * bB3\n",
    "#     self.W2 -= self.lr * bW2\n",
    "#     self.B2 -= self.lr * bB2\n",
    "#     self.W1 -= self.lr * bW1\n",
    "#     self.B1 -= self.lr * bB1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推定を行うメソッドを作成してください。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションによって出力された10個の確率の中で、最も高いものはどれかを判定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(self,X):\n",
    "#     \"\"\"予測\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     X : 説明変数\n",
    "#     \"\"\"\n",
    "#     # 順伝播処理\n",
    "#     self.forward(X)\n",
    "#     # 最も大きいインデックスをクラスとして採用\n",
    "#     return np.argmax(self.Z3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self,batch_size = 20,n_features = 784,n_nodes1 = 400,n_nodes2 = 200,n_output = 10,sigma = 0.02,lr = 0.01,epoch = 10, verbose = True):\n",
    "        \"\"\"変数の初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        verbose : 計算過程を出力するか否か\n",
    "        batch_size : ミニバッチのデータ数\n",
    "        n_features : 説明変数の数\n",
    "        n_nodes1 : 1層目のノードの数\n",
    "        n_nodes2 : 2層目のノードの数\n",
    "        n_output : 出力層のノードの数\n",
    "        sigma : 重みの初期化の際のガウス分布の標準偏差\n",
    "        lr : 学習率\n",
    "        epoch : 学習回数\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.n_features = n_features\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2 \n",
    "        self.n_output = n_output\n",
    "        self.sigma = sigma\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # 損失記録用\n",
    "        self.loss_train = []\n",
    "        self.loss_val = []\n",
    "        \n",
    "        # 使用する重みの初期化\n",
    "        # 重みとバイアス\n",
    "        self.W1 = self.sigma * np.random.randn(self.n_features,self.n_nodes1) #第一層の重み\n",
    "        self.W2 = self.sigma * np.random.randn(self.n_nodes1,self.n_nodes2) #第二層の重み\n",
    "        self.W3 = self.sigma * np.random.randn(self.n_nodes2,self.n_output) #第三層の重み\n",
    "        self.B1 = self.sigma * np.random.randn(1,self.n_nodes1) #第一層のバイアス\n",
    "        self.B2 = self.sigma * np.random.randn(1,self.n_nodes2) #第二層のバイアス\n",
    "        self.B3 = self.sigma * np.random.randn(1,self.n_output) #第三層のバイアス\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        # 学習回数分ループ\n",
    "        for _ in range(self.epoch):\n",
    "            \n",
    "            # ミニバッチのインスタンス化\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "            \n",
    "            # イテレータが停止するまで繰り返す\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # 順伝播\n",
    "                self.forward(mini_X_train)\n",
    "                # 逆伝播\n",
    "                self.back_proba(mini_X_train, mini_y_train)\n",
    "                \n",
    "            # ミニバッチ学習後のロス計算\n",
    "            self.forward(X)\n",
    "            self.loss_train.append(self.cross_entro_error(y, self.Z3))\n",
    "            \n",
    "            # 評価データがあるなら、こちらも計算\n",
    "            if X_val is not None:\n",
    "                self.forward(X_val)\n",
    "                self.loss_val.append(self.cross_entro_error(y_val, self.Z3))\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "    \n",
    "    # 活性化関数、今回はシグモイド関数\n",
    "    def _sigmoid(self,X):\n",
    "        return 1 /(1 + np.exp(-X))\n",
    "    \n",
    "    def tanh_function(self, A):\n",
    "        \n",
    "        return np.tanh(A)\n",
    "\n",
    "    # ソフトマックス関数\n",
    "    def _softmax(self,X):\n",
    "        #c = np.max(X)\n",
    "        exp_x = np.exp(X)\n",
    "        sum_exp_x = np.sum(exp_x,axis = 1).reshape(-1,1)\n",
    "        y = (exp_x / sum_exp_x)\n",
    "        return y\n",
    "\n",
    "    def forward(self,X):\n",
    "        \"\"\"1層目\"\"\"\n",
    "        self.A1 = X@self.W1 + self.B1\n",
    "        self.Z1 = self.tanh_function(self.A1)\n",
    "\n",
    "        \"\"\"2層目\"\"\"\n",
    "        self.A2 = self.Z1@self.W2 + self.B2\n",
    "        self.Z2 = self.tanh_function(self.A2)\n",
    "\n",
    "        \"\"\"3層目\"\"\"\n",
    "        self.A3 = self.Z2@self.W3 + self.B3\n",
    "        self.Z3 = self._softmax(self.A3)\n",
    "\n",
    "    def back_proba(self,X,y):\n",
    "        # X,yを入力すると3-1層を通過して最終出力値を返す仕組み\n",
    "\n",
    "        \"\"\"3層目\"\"\"\n",
    "        # 重みに対する勾配\n",
    "        bA3 = (self.Z3 - y)/self.batch_size\n",
    "        bW3 = self.Z2.T@bA3\n",
    "        # バイアスに対する勾配\n",
    "        bB3 = np.sum(bA3,axis = 0)\n",
    "\n",
    "        \"\"\"2層目\"\"\"\n",
    "        # 重みに対する勾配\n",
    "        bZ2 = bA3@self.W3.T\n",
    "        #bA2 = bZ2 * (1 - self._sigmoid(self.A2))*self._sigmoid(self.A2)\n",
    "        bA2 = bZ2 * (1 - self.tanh_function(self.A2)**2)\n",
    "        bW2 = self.Z1.T@bA2\n",
    "        # バイアスに対する勾配\n",
    "        bB2 = np.sum(bA2,axis = 0)\n",
    "\n",
    "        \"\"\"1層目\"\"\"\n",
    "        # 重みに対する勾配\n",
    "\n",
    "        bZ1 = bA2@self.W2.T\n",
    "        #bA1 = bZ1 * (1 - self._sigmoid(self.A1))*self._sigmoid(self.A1)\n",
    "        bA1 = bZ1 * (1 - self.tanh_function(self.A1)**2)\n",
    "        bW1 = X.T@bA1\n",
    "        # バイアスに対する勾配\n",
    "        bB1 = np.sum(bA1,axis = 0)\n",
    "\n",
    "        # 各勾配に学習率をかけて更新\n",
    "        self.W3 -= self.lr * bW3\n",
    "        self.B3 -= self.lr * bB3\n",
    "        self.W2 -= self.lr * bW2\n",
    "        self.B2 -= self.lr * bB2\n",
    "        self.W1 -= self.lr * bW1\n",
    "        self.B1 -= self.lr * bB1\n",
    "\n",
    "    # 交差エントロピー誤差\n",
    "    def cross_entro_error(self, y, Z):\n",
    "        \"\"\"損失関数　クロスエントロピー誤差\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 正解データ\n",
    "        Z : 予測値\n",
    "        \"\"\"\n",
    "        L = - np.sum(y * np.log(Z)) / len(y)\n",
    "        return L\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        # 順伝播処理\n",
    "        self.forward(X)\n",
    "        # 最も大きいインデックスをクラスとして採用\n",
    "        return np.argmax(self.Z3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# インスタンス化\n",
    "nn = ScratchSimpleNeuralNetrowkClassifier(epoch=10)\n",
    "# 学習\n",
    "nn.fit(X_train[:10000],y_train_one_hot[:10000], X_val, y_val_one_hot) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測\n",
    "pred_train = nn.predict(X_train)\n",
    "pred_test = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9041458333333333, 0.9078)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正解率\n",
    "accuracy_score(y_train, pred_train),accuracy_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】学習曲線のプロット"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習曲線をプロットしてください。\n",
    "\n",
    "\n",
    "ニューラルネットワークは過学習が発生しやすいため、学習曲線の確認が重要です。訓練データと検証データに対するエポックごとの損失（交差エントロピー誤差）を記録できるようにする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(1, nn.epoch+1)), nn.loss_train, label='train')\n",
    "plt.plot(list(range(1, nn.epoch+1)), nn.loss_val, label='test') # change\n",
    "plt.legend()\n",
    "plt.xticks(list(range(1, nn.epoch+1)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
